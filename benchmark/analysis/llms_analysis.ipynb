{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4e2c1-2472-4e6e-98e0-43cc029469e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:07:05.696665Z",
     "start_time": "2025-01-22T14:07:05.694870Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b89c4b-e5c8-4018-9dd1-5975d8bde959",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4c141b2-0bcf-493c-a8c2-9214396cf70f",
   "metadata": {},
   "source": [
    "import game_logic\n",
    "reload(game_logic)\n",
    "from game_logic import play_game, save_results_to_csv\n",
    "\n",
    "models = [\"gpt-4o-mini\", \"gpt-3.5-turbo-0125\", \"gpt-4-turbo\"] \n",
    "number_utterance = 20\n",
    "total_iterations = len(models) ** 2 * number_utterance # Total combinations of models with themselves\n",
    "\n",
    "# Single progress bar for all combinations\n",
    "pbar = tqdm(total=total_iterations, desc=\"Processing model combinations\")\n",
    "\n",
    "for model_1 in models:\n",
    "    for model_2 in models:\n",
    "        for i in range(number_utterance):  # 20 iterations per combination\n",
    "            results = play_game(model_1, model_2)\n",
    "            save_results_to_csv(results)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba6a69-b4b4-49b5-b680-f7f9c806b04e",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618254d7-46ce-494a-a70c-3dbef2854bc0",
   "metadata": {},
   "source": [
    "## Load the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b03d2-bd27-4826-bd0b-fd022fbc3d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:07:07.676817Z",
     "start_time": "2025-01-22T14:07:07.666205Z"
    }
   },
   "outputs": [],
   "source": [
    "from benchmark.analysis.utils.data_loading import load_csv\n",
    "\n",
    "# Load the CSV file\n",
    "df = load_csv('llm_game_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d8065-c37c-4547-a9ba-340ec4958db6",
   "metadata": {},
   "source": [
    "## Models-pairs performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ad2b6-f979-4d82-80fe-1b0dfcef6621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:07:12.009830Z",
     "start_time": "2025-01-22T14:07:11.999710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column 'Model Pair' treating the model combinations symmetrically\n",
    "df['Model Pair'] = df.apply(lambda row: tuple(sorted([row['Model 1'], row['Model 2']])), axis=1)\n",
    "\n",
    "\n",
    "# Compute success rate for all games\n",
    "df['Win'] = df['Status'].apply(lambda x: 'wins' in x)\n",
    "success_rate = df.groupby('Model Pair').agg(Success_Rate=('Win', 'mean'))\n",
    "\n",
    "# Filter only the rows where the status is 'wins'\n",
    "wins_df = df[df['Status'] == 'wins']\n",
    "wins_df['Round Length 1'] = wins_df['Past words player 1'].apply(len)\n",
    "wins_df['Round Length 2'] = wins_df['Past words player 2'].apply(len)\n",
    "wins_df['Average Round Length'] = (wins_df['Round Length 1'] + wins_df['Round Length 2']) / 2  # Average both players' rounds\n",
    "\n",
    "# Group by 'Model Pair' and compute the average rounds for winning games\n",
    "avg_rounds = wins_df.groupby('Model Pair').agg(Average_Rounds=('Average Round Length', 'mean'))\n",
    "\n",
    "# Merge success rate and average rounds into one result\n",
    "result = success_rate.merge(avg_rounds, on='Model Pair')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eafdb0-3a08-4709-b037-99532d9d1d2e",
   "metadata": {},
   "source": [
    "## Visualise convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566073e1e20d4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:13:30.982352Z",
     "start_time": "2025-01-22T14:07:14.492571Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "reload(embeding_visualization)\n",
    "from benchmark.analysis.utils.embeding_utils import get_embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Initialize dictionary to hold distances by model combination\n",
    "model_combinations = {}\n",
    "rounds = 6  # Calculate for the last 3 rounds, adapt as needed\n",
    "color_index = 0  # Initialize color index\n",
    "\n",
    "# Calculate embeddings and distances\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    if row['Status'] == \"wins\": \n",
    "        embeddings_1 = get_embeddings(row['Past words player 1'][-rounds:])\n",
    "        embeddings_2 = get_embeddings(row['Past words player 2'][-rounds:])\n",
    "        if len(embeddings_1) >= rounds:\n",
    "            row_distances = [euclidean(embeddings_1[i], embeddings_2[i]) for i in range(min(len(embeddings_1), len(embeddings_2)))]\n",
    "            # Generate both model keys (Model 1 vs Model 2 and vice versa)\n",
    "            model_key = (row['Model 1'], row['Model 2'])\n",
    "            reverse_model_key = (row['Model 2'], row['Model 1'])\n",
    "\n",
    "            # Check if either model_key or reverse_model_key exists\n",
    "            if model_key in model_combinations:\n",
    "                model_combinations[model_key].append(row_distances)\n",
    "            elif reverse_model_key in model_combinations:\n",
    "                model_combinations[reverse_model_key].append(row_distances)\n",
    "            else:\n",
    "                model_combinations[model_key] = [row_distances]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1c44f-0676-47c4-9472-e5802786ace1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:14:39.882217Z",
     "start_time": "2025-01-22T14:14:39.796803Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate and plot mean and std for the last few rounds for combinations with enough data\n",
    "plt.figure(figsize=(14, 8))\n",
    "colors = plt.cm.jet(np.linspace(0, 1, len(model_combinations)))\n",
    "\n",
    "color_index = 0  # Initialize color index\n",
    "for (model_key, distances_lists) in model_combinations.items():\n",
    "    if len(distances_lists) >= rounds:\n",
    "        # Calculate the mean and standard deviation for the last few rounds\n",
    "        last_games = distances_lists[-rounds:]  # Get the last 'rounds' games\n",
    "        last_games_array = np.array(last_games)\n",
    "        \n",
    "        # Calculating mean and std dev for the required rounds\n",
    "        mean_of_last_games = np.mean(last_games_array, axis=0)\n",
    "        std_of_last_games = np.std(last_games_array, axis=0)\n",
    "        \n",
    "        # Create time index for the rounds\n",
    "        time_index = np.arange(rounds)\n",
    "\n",
    "        # Plotting mean line\n",
    "        plt.plot(time_index, mean_of_last_games, label=f'{model_key} Last {rounds}', marker='o', color=colors[color_index])\n",
    "        \n",
    "        # Plotting the std deviation area around the mean\n",
    "        plt.fill_between(time_index, mean_of_last_games - std_of_last_games, mean_of_last_games + std_of_last_games, color=colors[color_index], alpha=0.3)\n",
    "        \n",
    "        color_index += 1  # Increment color index for the next model combination\n",
    "\n",
    "plt.xlabel('Game Index')\n",
    "plt.ylabel('Average Euclidean Distance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea30e65-bd07-409d-b9b2-e4d472302300",
   "metadata": {},
   "source": [
    "## Comparison to average of two last words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d6796323f129ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:14:50.826888Z",
     "start_time": "2025-01-22T14:14:50.825225Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb225d-6930-4d0b-9728-3e745e9c2599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:15:02.401023Z",
     "start_time": "2025-01-22T14:14:52.090907Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "reload(embeding_visualization)\n",
    "from benchmark.analysis.utils.embeding_utils import get_embeddings\n",
    "import numpy as np\n",
    "\n",
    "tryout = 4\n",
    "\n",
    "# Retrieving data\n",
    "words_player1 = df['Past words player 1'].iloc[tryout]\n",
    "words_player2 = df['Past words player 2'].iloc[tryout]\n",
    "embeddings_1 = get_embeddings(words_player1)\n",
    "embeddings_2 = get_embeddings(words_player2)\n",
    "\n",
    "# Calculating average embeddings\n",
    "average_embeddings = (np.array(embeddings_1) + np.array(embeddings_2)) / 2\n",
    "\n",
    "# Ensuring lengths are correct\n",
    "print(\"Length of Player 1 embeddings:\", len(embeddings_1))\n",
    "print(\"Length of Player 2 embeddings:\", len(embeddings_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289c46c-ef1c-4829-a38f-b6872bf1b9ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:15:02.498105Z",
     "start_time": "2025-01-22T14:15:02.420440Z"
    }
   },
   "outputs": [],
   "source": [
    "from benchmark.analysis.old_distance_calculous import plot_distances\n",
    "\n",
    "plot_distances(embeddings_1, embeddings_2, average_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4783334-af40-4058-9f40-4fd9b91e9fd0",
   "metadata": {},
   "source": [
    "### Table for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b14a2-6e29-4f5a-9696-2bc2d3fcadc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:31:27.383524Z",
     "start_time": "2025-01-22T15:09:58.957787Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "import benchmark.analysis.old_distance_calculous\n",
    "reload(benchmark.analysis.old_distance_calculous)\n",
    "from benchmark.analysis.old_distance_calculous import calculate_distances\n",
    "\n",
    "# Function to assign past words based on model\n",
    "def assign_past_words(row, model):\n",
    "    if row['Model 1'] == model:\n",
    "        row['Past words current Model'] = row['Past words player 1']\n",
    "        row['Past words other Model'] = row['Past words player 2']\n",
    "    else:\n",
    "        row['Past words current Model'] = row['Past words player 2']\n",
    "        row['Past words other Model'] = row['Past words player 1']\n",
    "    return row\n",
    "\n",
    "# List of models to analyze\n",
    "models = [\"gpt-4-turbo\", \"gpt-4o-mini\", \"gpt-3.5-turbo-0125\"]\n",
    "tqdm.pandas()\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    model_results = df[\n",
    "        df['Status'].isin(['wins', 'loses, too many rounds']) &\n",
    "        ((df['Model 1'] == model) | (df['Model 2'] == model))\n",
    "    ].copy()\n",
    "\n",
    "    model_results = model_results.apply(assign_past_words, axis=1, model=model)\n",
    "    model_results[['Distances to Previous', 'Distances to Average']] = model_results.progress_apply(\n",
    "        lambda row: pd.Series(calculate_distances(row)), axis=1\n",
    "    )\n",
    "\n",
    "    model_results['Average Distance to Previous'] = model_results['Distances to Previous'].apply(lambda x: np.mean(x) if x.size else 0)\n",
    "    model_results['Average Distance to Average'] = model_results['Distances to Average'].apply(lambda x: np.mean(x) if x.size else 0)\n",
    "    model_results['Std Dev Distance to Previous'] = model_results['Distances to Previous'].apply(lambda x: np.std(x) if x.size else 0)\n",
    "    model_results['Std Dev Distance to Average'] = model_results['Distances to Average'].apply(lambda x: np.std(x) if x.size else 0)\n",
    "\n",
    "    mean_distance_to_previous = model_results['Average Distance to Previous'].mean()\n",
    "    mean_distance_to_average = model_results['Average Distance to Average'].mean()\n",
    "    std_distance_to_previous = model_results['Std Dev Distance to Previous'].mean()\n",
    "    std_distance_to_average = model_results['Std Dev Distance to Average'].mean()\n",
    "    sample_size = len(model_results)\n",
    "    strategy = \"Mirroring Strategy\" if mean_distance_to_previous < mean_distance_to_average else \"Balancing Strategy\"\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model,\n",
    "        \"Mean Distance to Previous\": mean_distance_to_previous,\n",
    "        \"Mean Distance to Average\": mean_distance_to_average,\n",
    "        \"Std Dev Distance to Previous\": std_distance_to_previous,\n",
    "        \"Std Dev Distance to Average\": std_distance_to_average,\n",
    "        \"Number of Samples\": sample_size,\n",
    "        \"Predominant Strategy\": strategy\n",
    "    })\n",
    "\n",
    "# Create and display results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafb529-e28a-41a3-9cac-6a35ad5ea90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "225b1c50-152d-4aac-8710-69561e0a52e5",
   "metadata": {},
   "source": [
    "## Dynamics visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492114a2be5ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.analysis.visualization import create_fixed_color_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc2077-eeb7-4d82-b12d-a3260fb81728",
   "metadata": {},
   "source": [
    "### Gpt4-mini lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ab6895a92c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tryout = 2\n",
    "\n",
    "words_player1 = df['Past words player 1'].iloc[tryout]\n",
    "words_player2 = df['Past words player 2'].iloc[tryout]\n",
    "embeddings_1 = get_embeddings(df['Past words player 1'].iloc[tryout])\n",
    "embeddings_2 = get_embeddings(df['Past words player 2'].iloc[tryout])\n",
    "\n",
    "\n",
    "# merge the embeddings\n",
    "embeddings = embeddings_1 + embeddings_2\n",
    "\n",
    "# Use PCA to reduce to 3 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit(np.array(embeddings))\n",
    "reduced_embeddings_1 = pca.transform(embeddings_1)\n",
    "reduced_embeddings_2 = pca.transform(embeddings_2)\n",
    "\n",
    "# Create 3D scatter plot for player 1 and player 2\n",
    "trace1 = go.Scatter3d(\n",
    "    x=reduced_embeddings_1[:, 0],\n",
    "    y=reduced_embeddings_1[:, 1],\n",
    "    z=reduced_embeddings_1[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=4, color='blue'),\n",
    "    text=np.arange(len(words_player1)),\n",
    "    name='Model 1'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter3d(\n",
    "    x=reduced_embeddings_2[:, 0],\n",
    "    y=reduced_embeddings_2[:, 1],\n",
    "    z=reduced_embeddings_2[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=4, color='red'),\n",
    "    text=np.arange(len(words_player2)),\n",
    "    name='Model 2'\n",
    ")\n",
    "\n",
    "if words_player2[-1] == words_player1[-1]:\n",
    "    print(\"won\")\n",
    "    # Add the last point as a star for Player 2\n",
    "    last_point_player = go.Scatter3d(\n",
    "        x=[reduced_embeddings_2[-1, 0]],\n",
    "        y=[reduced_embeddings_2[-1, 1]],\n",
    "        z=[reduced_embeddings_2[-1, 2]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=8, color='green', symbol=\"diamond-open\"),\n",
    "        text=[words_player2[-1]],\n",
    "        name='Final word'\n",
    "    )\n",
    "\n",
    "\n",
    "# Create gradient lines for both players using Plotly colormaps\n",
    "lines_player1 = create_fixed_color_lines(reduced_embeddings_1, len(words_player1), 'blue')\n",
    "lines_player2 = create_fixed_color_lines(reduced_embeddings_2, len(words_player2), 'red')\n",
    "\n",
    "# Combine all traces\n",
    "data = [trace1, trace2] + lines_player1 + lines_player2\n",
    "if words_player2[-1] == words_player1[-1]:\n",
    "    data = data + [last_point_player]\n",
    "# Define layout with larger figure size\n",
    "layout = go.Layout(\n",
    "    title='3D Scatter Plot with Colormap Gradient Lines',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='PCA1'),\n",
    "        yaxis=dict(title='PCA2'),\n",
    "        zaxis=dict(title='PCA3'),\n",
    "    ),\n",
    "    legend_title_text='Models',\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Create figure and show\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376cd208-7f0f-404c-92cf-618bbf771839",
   "metadata": {},
   "source": [
    "### Win between gpt-4-turbo,gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e03a5f-9426-423a-a012-50331149e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_player1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecff551-150c-488d-ba8c-b79ce40f7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_player2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c117d32-f05e-4b49-99b4-596fb3c8927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tryout = 125\n",
    "\n",
    "words_player1 = df['Past words player 1'].iloc[tryout]\n",
    "words_player2 = df['Past words player 2'].iloc[tryout]\n",
    "embeddings_1 = get_embeddings(df['Past words player 1'].iloc[tryout])\n",
    "embeddings_2 = get_embeddings(df['Past words player 2'].iloc[tryout])\n",
    "\n",
    "\n",
    "# merge the embeddings\n",
    "embeddings = embeddings_1 + embeddings_2\n",
    "\n",
    "# Use PCA to reduce to 3 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit(np.array(embeddings))\n",
    "reduced_embeddings_1 = pca.transform(embeddings_1)\n",
    "reduced_embeddings_2 = pca.transform(embeddings_2)\n",
    "\n",
    "# Create 3D scatter plot for player 1 and player 2\n",
    "trace1 = go.Scatter3d(\n",
    "    x=reduced_embeddings_1[:, 0],\n",
    "    y=reduced_embeddings_1[:, 1],\n",
    "    z=reduced_embeddings_1[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=4, color='blue'),\n",
    "    text=np.arange(len(words_player1)),\n",
    "    name='Model 1'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter3d(\n",
    "    x=reduced_embeddings_2[:, 0],\n",
    "    y=reduced_embeddings_2[:, 1],\n",
    "    z=reduced_embeddings_2[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=4, color='red'),\n",
    "    text=np.arange(len(words_player2)),\n",
    "    name='Model 2'\n",
    ")\n",
    "\n",
    "if words_player2[-1] == words_player1[-1]:\n",
    "    print(\"won\")\n",
    "    # Add the last point as a star for Player 2\n",
    "    last_point_player = go.Scatter3d(\n",
    "        x=[reduced_embeddings_2[-1, 0]],\n",
    "        y=[reduced_embeddings_2[-1, 1]],\n",
    "        z=[reduced_embeddings_2[-1, 2]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=8, color='green', symbol=\"diamond-open\"),\n",
    "        text=[words_player2[-1]],\n",
    "        name='Final word'\n",
    "    )\n",
    "\n",
    "\n",
    "# Create gradient lines for both players using Plotly colormaps\n",
    "lines_player1 = create_fixed_color_lines(reduced_embeddings_1, len(words_player1), 'blue')\n",
    "lines_player2 = create_fixed_color_lines(reduced_embeddings_2, len(words_player2), 'red')\n",
    "\n",
    "# Combine all traces\n",
    "data = [trace1, trace2] + lines_player1 + lines_player2\n",
    "if words_player2[-1] == words_player1[-1]:\n",
    "    data = data + [last_point_player]\n",
    "# Define layout with larger figure size\n",
    "layout = go.Layout(\n",
    "    title='3D Scatter Plot with Colormap Gradient Lines',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='PCA1'),\n",
    "        yaxis=dict(title='PCA2'),\n",
    "        zaxis=dict(title='PCA3'),\n",
    "    ),\n",
    "    legend_title_text='Models',\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Create figure and show\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb3f58-fa36-4bdc-8166-5d640b93e86a",
   "metadata": {},
   "source": [
    "### Win between gpt-4-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426a926-0fc0-4c44-9552-bc81cd50e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tryout = 175\n",
    "\n",
    "words_player1 = df['Past words player 1'].iloc[tryout]\n",
    "words_player2 = df['Past words player 2'].iloc[tryout]\n",
    "embeddings_1 = get_embeddings(df['Past words player 1'].iloc[tryout])\n",
    "embeddings_2 = get_embeddings(df['Past words player 2'].iloc[tryout])\n",
    "\n",
    "\n",
    "# merge the embeddings\n",
    "embeddings = embeddings_1 + embeddings_2\n",
    "\n",
    "# Use PCA to reduce to 3 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit(np.array(embeddings))\n",
    "reduced_embeddings_1 = pca.transform(embeddings_1)\n",
    "reduced_embeddings_2 = pca.transform(embeddings_2)\n",
    "\n",
    "\n",
    "# Create 3D scatter plot for player 1 and player 2\n",
    "trace1 = go.Scatter3d(\n",
    "    x=reduced_embeddings_1[:, 0],\n",
    "    y=reduced_embeddings_1[:, 1],\n",
    "    z=reduced_embeddings_1[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=4, color='blue'),\n",
    "    text=np.arange(len(words_player1)),\n",
    "    name='Model 1'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter3d(\n",
    "    x=reduced_embeddings_2[:, 0],\n",
    "    y=reduced_embeddings_2[:, 1],\n",
    "    z=reduced_embeddings_2[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=4, color='red'),\n",
    "    text=np.arange(len(words_player2)),\n",
    "    name='Model 2'\n",
    ")\n",
    "\n",
    "if words_player2[-1] == words_player1[-1]:\n",
    "    print(\"won\")\n",
    "    # Add the last point as a star for Player 2\n",
    "    last_point_player = go.Scatter3d(\n",
    "        x=[reduced_embeddings_2[-1, 0]],\n",
    "        y=[reduced_embeddings_2[-1, 1]],\n",
    "        z=[reduced_embeddings_2[-1, 2]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=8, color='green', symbol=\"diamond-open\"),\n",
    "        text=[words_player2[-1]],\n",
    "        name='Final word'\n",
    "    )\n",
    "\n",
    "\n",
    "# Create gradient lines for both players using Plotly colormaps\n",
    "lines_player1 = create_fixed_color_lines(reduced_embeddings_1, len(words_player1), 'blue')\n",
    "lines_player2 = create_fixed_color_lines(reduced_embeddings_2, len(words_player2), 'red')\n",
    "\n",
    "# Combine all traces\n",
    "data = [trace1, trace2] + lines_player1 + lines_player2\n",
    "if words_player2[-1] == words_player1[-1]:\n",
    "    data = data + [last_point_player]\n",
    "# Define layout with larger figure size\n",
    "layout = go.Layout(\n",
    "    title='3D Scatter Plot with Colormap Gradient Lines',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='PCA1'),\n",
    "        yaxis=dict(title='PCA2'),\n",
    "        zaxis=dict(title='PCA3'),\n",
    "    ),\n",
    "    legend_title_text='Models',\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Create figure and show\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5861469-dcb2-41af-bf15-9bf8019254b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387fbac-8427-4eaa-b5f6-4c9f9cff563d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69f2aa-aff5-45ff-a513-43ca784737b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864d832-7ff6-467a-8834-aad8ee897b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e802b5-0e9f-4f5b-a625-f362b9e48aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "words_env",
   "language": "python",
   "name": "words_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
