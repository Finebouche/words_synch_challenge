{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0521c0a-9c7d-4b3b-8c70-4d257ec05b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T15:01:21.762929Z",
     "start_time": "2025-03-31T15:01:16.797631Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils.embeding_utils import (get_embeddings_for_table, calculate_pca_for_embeddings)\n",
    "from utils.data_loading import load_sql_data, load_csv\n",
    "import pingouin as pg\n",
    "import numpy\n",
    "\n",
    "db_name = \"clean_db.db\"\n",
    "csv_name = \"data/games.csv\"\n",
    "\n",
    "# 1) Load the data\n",
    "if not os.path.exists(csv_name):\n",
    "    players_df, games_df = load_sql_data(db_name)\n",
    "    games_df.to_csv(csv_name, index=False)\n",
    "else:\n",
    "    games_df = pd.read_csv(csv_name)\n",
    "\n",
    "games_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72544bb-3c8f-43e2-aeee-441991b16b0d",
   "metadata": {},
   "source": [
    "# Calculate embedings and CL scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db3d1e-dbf3-4a02-b584-82df8f39146b",
   "metadata": {},
   "source": [
    "## Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bdef01-8920-4071-845f-70f096a233e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"word2vec\"\n",
    "games_df = get_embeddings_for_table( games_df, model_name=embedding_model,)\n",
    "games_df = calculate_pca_for_embeddings(\n",
    "    games_df,\n",
    "    model_name=embedding_model,\n",
    "    num_pca_components=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26f1a6-5538-4e14-9e0b-0946b4c7ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5009c1-0e7b-4852-ab2a-6b954c577972",
   "metadata": {},
   "source": [
    "## CL scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f948d1-074c-431c-bddf-14b210ccf87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from utils import game_statistics\n",
    "\n",
    "reload(game_statistics)\n",
    "from utils.game_statistics import calculate_game_metrics_per_player, calculate_game_metrics_per_configuration\n",
    "\n",
    "player_metrics = calculate_game_metrics_per_configuration(games_df, plot_box=True, separate_per_config=True)\n",
    "print(\"Success Rate and Average Rounds for Winning Games:\")\n",
    "print(player_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da49305-f807-4a07-9977-cdeeda9e78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "player_metrics = calculate_game_metrics_per_player(games_df)\n",
    "print(\"Average Number of Rounds and Success Rate per Player:\")\n",
    "print(player_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cab74-0277-4cd6-bb6c-5e9b06571271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import strategy_analysis\n",
    "reload(strategy_analysis)\n",
    "from strategy_analysis import strategy_analysis\n",
    "\n",
    "results_df = strategy_analysis(games_df, embedding_model, use_pca=False, use_conceptual_linking_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d5425-df21-4779-9037-f68799071632",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_results_file = \"data/results.csv\"\n",
    "\n",
    "# Save results with strategies to CSV but only a subset of columns\n",
    "cols_to_save = [\n",
    "    \"gameId\",\n",
    "    \"playerId\",\n",
    "    \"player1Id\",\n",
    "    \"player2Id\",\n",
    "    \"botId\",\n",
    "    \"status\",\n",
    "    \"roundCount\",\n",
    "    \"wordsPlayed1\",\n",
    "    \"wordsPlayed2\",\n",
    "    \"gameConfigPlayer1\",\n",
    "    \"gameConfigPlayer2\",\n",
    "    \"gameConfig\",\n",
    "    \"word_my\",\n",
    "    \"word_opponent\",\n",
    "    \"surveyAnswers1\",\n",
    "    \"surveyAnswers2\",\n",
    "    \"semantic_strategy_name\",\n",
    "    \"quantitative_strategy_name\",\n",
    "    \"conceptual_linking_score_my\",\n",
    "    \"conceptual_linking_score_opponent\",\n",
    "    \"collocation_score_my\",\n",
    "    \"collocation_score_opponent\",\n",
    "]\n",
    "results_df_partial = results_df[cols_to_save]\n",
    "results_df_partial.to_csv(strategy_results_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2aa50a-ed0f-4106-a5b2-f066b714ae22",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d533d-6f70-434a-b924-71a79f55061f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadcb21e-4c34-4586-97b1-14d13b070dea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T15:03:57.649294Z",
     "start_time": "2025-03-31T15:03:57.638657Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "strategy_results_file = \"data/results.csv\"\n",
    "# read the result file from csv\n",
    "results_df_partial = pd.read_csv(strategy_results_file)\n",
    "results_df = results_df_partial.copy()\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae86c7-df56-40c1-a36c-f837a9bc88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id_array = [\"DvplG2Kz\", \"IfM2wWHp\", \"1zx9ju2S\", \"BVSUju5U\", \"lW70ICul\", \"OZ52imkd\", \"GorQHcOB\", \"8PSrn9JD\", \"u5LgXigL\",\n",
    "                  \"1Ax1SPCe\", \"l8ND7njk\", \"sfiXibsa\", \"PvUHGrDy\", \"MO2pWpjE\", \"gsbTiZwO\", \"gDnhDODC\", \"Ska8rixW\", \"6DbWtL5r\",\n",
    "                  \"TCFqdHBb\", \"wQhT1jrv\"]\n",
    "filtered_df = results_df[results_df[\"playerId\"].isin(player_id_array)]\n",
    "filtered_df = filtered_df[(filtered_df[\"roundCount\"] > 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28864b-07de-4429-a5b0-b63be965dc55",
   "metadata": {},
   "source": [
    "## Conceptual linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa4a3b-7b39-469d-899b-5f457f20b96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from strategy_analysis.conceptual_linking_analysis import conceptual_linking_score\n",
    "\n",
    "def conceptual_linking_scores(player_games):\n",
    "    player_games['conceptual_linking_score_my'] = None\n",
    "\n",
    "    for index, game in player_games.iterrows():\n",
    "        # Evaluate or directly use the lists of words played by \"myself\"\n",
    "        words_played_my = game['wordsPlayedMy']\n",
    "        if not isinstance(words_played_my, list):\n",
    "            words_played_my = eval(words_played_my)\n",
    "\n",
    "        num_rounds = len(words_played_my)\n",
    "\n",
    "        conceptual_linking_my_list = []\n",
    "\n",
    "        for i in range(num_rounds):\n",
    "            if i == 0:\n",
    "                # First round has no previous word to compare, so we set score to 0 or None\n",
    "                cl_score_my = 0\n",
    "            else:\n",
    "                current_word = words_played_my[i]\n",
    "                prev_word = words_played_my[i - 1]\n",
    "\n",
    "                cl_score_my = conceptual_linking_score(current_word, prev_word, verbose=True)\n",
    "\n",
    "\n",
    "            conceptual_linking_my_list.append(cl_score_my)\n",
    "\n",
    "        player_games.at[index, 'conceptual_linking_score_my'] = conceptual_linking_my_list\n",
    "\n",
    "    return player_games\n",
    "\n",
    "cl_df = conceptual_linking_scores(selected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca10e0-21b8-4063-ab47-2392fecb9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c53fa-c6bd-49d5-aecf-b31c8b1c1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "def plot_score_heatmap(df, score_columns=(\"score_my\", \"score_opponent\"), max_num_round=16):\n",
    "    \n",
    "    config_map = {\n",
    "        \"human_vs_bot_(bot_shown)\":     \"LLM-vs-Human (AI shown)\",\n",
    "        \"human_vs_bot_(human_shown)\":   \"LLM-vs-Human (Human shown)\",\n",
    "    }\n",
    "    df['gameConfig'] = df['gameConfig'].map(config_map)\n",
    "    df = df[df['gameConfig'].isin(config_map.values())]\n",
    "    \n",
    "    def parse_score_value(val):\n",
    "        # If the value is a string, try to convert it to a list or array\n",
    "        if isinstance(val, str):\n",
    "            try:\n",
    "                val = ast.literal_eval(val)\n",
    "            except Exception:\n",
    "                return 0\n",
    "        # Now, if it's a list or numpy array, compute the mean for the first max_num_round items\n",
    "        if isinstance(val, (list, np.ndarray)) and len(val) > 0:\n",
    "            return np.nanmean(val[:max_num_round])\n",
    "        return 0\n",
    "    \n",
    "    for col in score_columns:\n",
    "        df[col + '_mean'] = df[col].apply(parse_score_value)\n",
    "    \n",
    "    agg_cols = [col + '_mean' for col in score_columns]\n",
    "    grouped = df.groupby('gameConfig')[agg_cols].mean().reset_index()\n",
    "    \n",
    "    print(agg_cols)\n",
    "    print(grouped[['gameConfig'] + agg_cols])\n",
    "    \n",
    "    matrix = grouped.set_index('gameConfig')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    data = matrix.values\n",
    "    vmin = np.nanmin(data)\n",
    "    vmax = np.nanmax(data)\n",
    "    \n",
    "    cax = ax.imshow(data, cmap='viridis', aspect='auto', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    cbar = fig.colorbar(cax, ax=ax)\n",
    "    \n",
    "    x_label_map = {\n",
    "        score_columns[0]: \"Bot\\nPrevious Word\",\n",
    "        score_columns[1]: \"Partner\\nPrevious Word\"\n",
    "    }\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(matrix.columns)))\n",
    "    x_labels = [x_label_map.get(col.replace('_mean',''), col.replace('_mean','')) for col in matrix.columns]\n",
    "    ax.set_xticklabels(x_labels, rotation=0, ha='center')\n",
    "    \n",
    "    ax.set_yticks(np.arange(len(matrix.index)))\n",
    "    ax.set_yticklabels(matrix.index)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            val = data[i, j]\n",
    "            if not np.isnan(val):\n",
    "                text_color = 'white' if val < (vmin + vmax) / 2 else 'black'\n",
    "                ax.text(j, i, f\"{val:.2f}\", ha='center', va='center', color=text_color)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming cl_df is your original DataFrame\n",
    "cl_df_copy = cl_df.copy()\n",
    "plot_score_heatmap(cl_df_copy, score_columns=(\"conceptual_linking_score_my\", \"conceptual_linking_score_opponent\"), max_num_round=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d5e65-598c-4e57-a651-e38ebd91a150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T15:03:58.776716Z",
     "start_time": "2025-03-31T15:03:58.768740Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_score_heatmap(results_df,\n",
    "                       score_columns=(\"score_my\", \"score_opponent\"),\n",
    "                       max_num_round=16):\n",
    "\n",
    "    # 1 – 4 ▸ identical data-prep as before … -----------------------------------\n",
    "    results_df['gameConfig'] = results_df.apply(\n",
    "        lambda row: row['gameConfigPlayer1']\n",
    "        if row['playerId'] == row['player1Id']\n",
    "        else (row['gameConfigPlayer2']\n",
    "              if row['playerId'] == row['player2Id']\n",
    "              else 'Unknown'),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    config_map = {\n",
    "        \"human_vs_bot_(bot_shown)\":     \"vs-LLM\\n(AI shown)\",\n",
    "        \"human_vs_bot_(human_shown)\":   \"vs-LLM\\n(Human shown)\",\n",
    "        \"human_vs_human_(human_shown)\": \"vs-Human\\n(Human shown)\",\n",
    "        \"human_vs_human_(bot_shown)\":   \"vs-Human\\n(AI shown)\",\n",
    "    }\n",
    "    results_df['gameConfig'] = results_df['gameConfig'].map(config_map)\\\n",
    "                                                     .fillna(results_df['gameConfig'])\n",
    "\n",
    "    for col in score_columns:\n",
    "        results_df[col + '_mean'] = results_df[col].apply(eval).apply(\n",
    "            lambda arr: np.nanmean(arr[:max_num_round])\n",
    "            if isinstance(arr, (list, np.ndarray)) and len(arr) > 0 else 0\n",
    "        )\n",
    "\n",
    "    agg_cols = [col + '_mean' for col in score_columns]\n",
    "    grouped  = results_df.groupby('gameConfig')[agg_cols].mean().reset_index()\n",
    "\n",
    "    # 5  ▸ matrix for the plot --------------------------------------------------\n",
    "    matrix = grouped.set_index('gameConfig')\n",
    "    data   = matrix.values\n",
    "\n",
    "    # 6  ▸ bubble heat-map ------------------------------------------------------\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # colour-mapping and colour-bar (without outline)\n",
    "    norm = Normalize(vmin=np.nanmin(data), vmax=np.nanmax(data))\n",
    "    sm   = ScalarMappable(norm=norm, cmap='viridis')\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.2f'))\n",
    "    cbar.outline.set_visible(False)              # ⬅︎ remove colour-bar edge\n",
    "\n",
    "    # parameters controlling look & feel\n",
    "    h_spacing  = 1.3      # horizontal gap multiplier\n",
    "    max_radius = 0.40     # absolute max radius (largest bubble)\n",
    "\n",
    "    n_rows, n_cols = data.shape\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            val = data[i, j]\n",
    "            if np.isnan(val) or val <= 0:\n",
    "                continue                          # skip empty / non-positive\n",
    "            # radius ∝ √value  (so *area* ∝ value)\n",
    "            radius = np.sqrt(val / norm.vmax) * max_radius\n",
    "            x      = j * h_spacing\n",
    "            y      = i\n",
    "\n",
    "            ax.add_patch(\n",
    "                Circle((x, y), radius=radius,\n",
    "                       facecolor=sm.to_rgba(val),\n",
    "                       edgecolor='grey', lw=0.5)\n",
    "            )\n",
    "\n",
    "            txt_col = 'white' if val < (norm.vmin + norm.vmax) / 2 else 'black'\n",
    "            ax.text(x, y, f\"{val:.2f}\", ha='center', va='center',\n",
    "                    fontweight='bold', color=txt_col)\n",
    "\n",
    "    # ticks, labels, limits -----------------------------------------------------\n",
    "    xtick_pos = [k * h_spacing for k in range(n_cols)]\n",
    "    ax.set_xticks(xtick_pos)\n",
    "    ax.set_xticklabels(\n",
    "        [\"Player\\nPrevious Word\", \"Partner's\\nPrevious Word\"], ha='center'\n",
    "    )\n",
    "\n",
    "    ax.set_yticks(np.arange(n_rows))\n",
    "    ax.set_yticklabels(matrix.index)\n",
    "\n",
    "    ax.set_xlim(-0.5 * h_spacing,\n",
    "                (n_cols - 1) * h_spacing + 0.5 * h_spacing)\n",
    "    ax.set_ylim(n_rows - 0.5, -0.5)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # hide frame but keep ticks\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# we don't take into account the unfinished game\n",
    "filtered_df_cl = filtered_df[results_df[\"status\"].isin([\"won\", \"lost\"])]\n",
    "\n",
    "plot_score_heatmap(filtered_df_cl, score_columns=(\"conceptual_linking_score_my\", \"conceptual_linking_score_opponent\"), max_num_round=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3944fae0-3382-42f3-b3f5-769d51c2e2c2",
   "metadata": {},
   "source": [
    "## Quantitative strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f6df5-3132-47d2-963d-3c938c9ff02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import strategy_analysis.strategy_analysis_main\n",
    "reload(strategy_analysis.strategy_analysis_main)\n",
    "from strategy_analysis.strategy_analysis_main import plot_strategy_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71b8e5-b45b-4100-91b4-2cbbd64e8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_strategy_heatmap(filtered_df, strategy_col=\"quantitative_strategy_name\", groupby='gameConfig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49180e9f-517c-42a7-be4b-18d91a84e956",
   "metadata": {},
   "source": [
    "## Questionnaire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d94c80f-5f0a-43cd-9655-bd7554c4469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_survey_fields(survey, keys):\n",
    "    \"\"\"\n",
    "    Given a survey answer (expected to be a list with one dictionary),\n",
    "    extract the values for each key in `keys` and convert them to numeric.\n",
    "    Returns a dictionary mapping each key to its numeric value (or NaN if not available).\n",
    "    \"\"\"\n",
    "    if not isinstance(survey, list):\n",
    "        survey = eval(survey)\n",
    "    if isinstance(survey, list) and len(survey) > 0:\n",
    "        d = survey[0]\n",
    "        return { key: pd.to_numeric(d.get(key, np.nan), errors='coerce') for key in keys }\n",
    "    else:\n",
    "        return { key: np.nan for key in keys }\n",
    "\n",
    "def compile_survey_scores_for_keys(df, keys):\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, extract the survey answers from both\n",
    "    surveyAnswer1 and surveyAnswer2 for the given keys, then compute\n",
    "    the average for each key (ignoring NaN values).\n",
    "    The resulting averages are stored in new columns with the same key names.\n",
    "    \"\"\"\n",
    "    # Extract dictionaries for each survey column\n",
    "    survey1 = df['surveyAnswers1'].apply(lambda x: extract_survey_fields(x, keys))\n",
    "    survey2 = df['surveyAnswers2'].apply(lambda x: extract_survey_fields(x, keys))\n",
    "    \n",
    "    # For each key, combine the values from survey1 and survey2 by averaging.\n",
    "    for key in keys:\n",
    "        def average_two(s1, s2):\n",
    "            values = [v for v in (s1.get(key), s2.get(key)) if not pd.isna(v)]\n",
    "            return np.mean(values) if values else np.nan\n",
    "        df[key] = [average_two(s1, s2) for s1, s2 in zip(survey1, survey2)]\n",
    "    return df\n",
    "\n",
    "def compile_average_ratings_by_config(results_df, keys):\n",
    "    \"\"\"\n",
    "    Computes a game configuration column based on the player's perspective,\n",
    "    extracts the survey values for the provided keys, and then groups by game\n",
    "    configuration to compute the average for each key.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame that must include:\n",
    "          - 'surveyAnswer1' and 'surveyAnswer2' (lists with one dictionary each),\n",
    "          - 'playerId', 'player1Id', 'player2Id',\n",
    "          - 'gameConfigPlayer1' and 'gameConfigPlayer2'.\n",
    "    keys : list of str\n",
    "        The keys from the survey dictionaries to extract and average.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame grouped by game configuration with average values for each key.\n",
    "    \"\"\"\n",
    "    # Create a new 'gameConfig' column based on the player's perspective.\n",
    "    results_df['gameConfig'] = results_df.apply(\n",
    "        lambda row: row['gameConfigPlayer1']\n",
    "                    if row['playerId'] == row['player1Id']\n",
    "                    else (row['gameConfigPlayer2']\n",
    "                          if row['playerId'] == row['player2Id']\n",
    "                          else 'Unknown'),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Extract and average the survey values for the given keys.\n",
    "    results_df = compile_survey_scores_for_keys(results_df, keys)\n",
    "    \n",
    "    # Group by game configuration and compute the mean for each specified key.\n",
    "    grouped = results_df.groupby('gameConfig')[keys].mean().reset_index()\n",
    "    return grouped\n",
    "\n",
    "# Example usage:\n",
    "# Suppose you want to analyze these keys:\n",
    "keys_to_average = [\n",
    "    'otherPlayerUnderstoodYourStrategies',\n",
    "    'didYouUnderstandOtherPlayerStrategy',\n",
    "    'otherPlayerRating',\n",
    "    'connectionFeeling'\n",
    "]\n",
    "\n",
    "grouped_ratings = compile_average_ratings_by_config(filtered_df, keys_to_average)\n",
    "grouped_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2445ec3-d643-4c13-95a9-5a13e9b26802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def extract_categorical_responses(survey, key, categories):\n",
    "    \"\"\"\n",
    "    For a given survey answer (expected to be a list with one dictionary),\n",
    "    extract responses for the specified key and compute the relative frequency\n",
    "    for each category.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    survey : list\n",
    "        Expected to be a list with one dictionary.\n",
    "    key : str\n",
    "        The dictionary key to extract (e.g., \"quantitativeOtherPlayerStrategy\").\n",
    "    categories : iterable of str\n",
    "        Allowed responses.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary mapping each category to the fraction of responses.\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    if not isinstance(survey, list):\n",
    "        survey = eval(survey)\n",
    "        \n",
    "    if isinstance(survey, list) and len(survey) > 0:\n",
    "        d = survey[0]\n",
    "        val = d.get(key, None)\n",
    "        # If the value is a list, use its elements; otherwise, treat it as a single value.\n",
    "        if isinstance(val, list):\n",
    "            responses.extend(val)\n",
    "        elif val is not None:\n",
    "            responses.append(val)\n",
    "    total = len(responses)\n",
    "    if total == 0:\n",
    "        return {cat: np.nan for cat in categories}\n",
    "    freq = {cat: responses.count(cat) / total for cat in categories}\n",
    "    return freq\n",
    "\n",
    "def compile_quantitative_other_strategy(df, key, categories):\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, extract the categorical responses for the given key\n",
    "    from both surveyAnswer1 and surveyAnswer2. New columns are created for each category,\n",
    "    with names formatted as \"{key}_{category}\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain 'surveyAnswer1' and 'surveyAnswer2'.\n",
    "    key : str\n",
    "        e.g. \"quantitativeOtherPlayerStrategy\".\n",
    "    categories : iterable of str\n",
    "        Allowed responses (e.g. (\"mirroring\", \"stayingClose\", \"averaging\")).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with additional columns for each category.\n",
    "    \"\"\"\n",
    "    extracted = df.apply(\n",
    "        lambda row: extract_categorical_responses(row['surveyAnswers1'], key, categories) if pd.notna(row['surveyAnswers1']) else {},\n",
    "        axis=1\n",
    "    )\n",
    "    # Also extract for surveyAnswer2 and then average the two.\n",
    "    extracted2 = df.apply(\n",
    "        lambda row: extract_categorical_responses(row['surveyAnswers2'], key, categories) if pd.notna(row['surveyAnswers2']) else {},\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    # For each row, average the values from the two surveys for each category.\n",
    "    for cat in categories:\n",
    "        def avg_two(s1, s2):\n",
    "            vals = []\n",
    "            if s1.get(cat) is not None and not pd.isna(s1.get(cat)):\n",
    "                vals.append(s1.get(cat))\n",
    "            if s2.get(cat) is not None and not pd.isna(s2.get(cat)):\n",
    "                vals.append(s2.get(cat))\n",
    "            return np.mean(vals) if vals else np.nan\n",
    "        df[key + '_' + cat] = [avg_two(s1, s2) for s1, s2 in zip(extracted, extracted2)]\n",
    "    return df\n",
    "\n",
    "def plot_quantitative_other_strategy_heatmap(results_df,\n",
    "                                             key=\"quantitativeOtherPlayerStrategy\",\n",
    "                                             categories=(\"averaging\", \"mirroring\", \"stayingClose\"),\n",
    "                                             groupby='gameConfig'):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of the average relative frequency of each quantitative other-player strategy\n",
    "    per game configuration.\n",
    "    \n",
    "    The DataFrame must contain:\n",
    "      - 'surveyAnswer1' and 'surveyAnswer2' (each a list with one dictionary),\n",
    "      - 'playerId', 'player1Id', and 'player2Id',\n",
    "      - 'gameConfigPlayer1' and 'gameConfigPlayer2'.\n",
    "      \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_df : pd.DataFrame\n",
    "        The input DataFrame.\n",
    "    key : str, default \"quantitativeOtherPlayerStrategy\"\n",
    "        The survey key to extract.\n",
    "    categories : tuple of str, default (\"mirroring\", \"stayingClose\", \"averaging\")\n",
    "        The allowed responses.\n",
    "    groupby : str, default 'gameConfig'\n",
    "        How to group rows. In this function, grouping is done by game configuration\n",
    "        based on the player's perspective.\n",
    "    \"\"\"\n",
    "    # 1) Create a new 'gameConfig' column based on player's perspective.\n",
    "    results_df['gameConfig'] = results_df.apply(\n",
    "        lambda row: row['gameConfigPlayer1']\n",
    "                    if row['playerId'] == row['player1Id']\n",
    "                    else (row['gameConfigPlayer2']\n",
    "                          if row['playerId'] == row['player2Id']\n",
    "                          else 'Unknown'),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 2) Extract the categorical responses for quantitativeOtherPlayerStrategy.\n",
    "    results_df = compile_quantitative_other_strategy(results_df, key, categories)\n",
    "    \n",
    "    # 3) Identify the new columns.\n",
    "    new_cols = [f\"{key}_{cat}\" for cat in categories]\n",
    "\n",
    "       # 2) Map the original config strings to the requested labels.\n",
    "    config_map = {\n",
    "        \"human_vs_bot_(bot_shown)\":     \"vs-LLM\\n(AI shown)\",\n",
    "        \"human_vs_bot_(human_shown)\":   \"vs-LLM\\n(Human shown)\",\n",
    "        \"human_vs_human_(human_shown)\": \"vs-Human\\n(Human shown)\",\n",
    "        \"human_vs_human_(bot_shown)\":   \"vs-Human\\n(AI shown)\",\n",
    "    }\n",
    "    # Apply the mapping, leaving other configs unchanged.\n",
    "    results_df['gameConfig'] = results_df['gameConfig'].map(config_map).fillna(results_df['gameConfig'])\n",
    "    \n",
    "    \n",
    "    # 4) Group by game configuration and compute the average for each new column.\n",
    "    grouped = results_df.groupby('gameConfig')[new_cols].mean().reset_index()\n",
    "    \n",
    "    # 5) Create a matrix for the heatmap: rows are game configurations, columns are the strategy categories.\n",
    "    matrix = grouped.set_index('gameConfig')\n",
    "    \n",
    "\n",
    "    # 6) Plot with circles instead of imshow squares.\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    data = matrix.values\n",
    "    n_rows, n_cols = data.shape\n",
    "\n",
    "    # Prepare the colormap normalization and a ScalarMappable for the colorbar\n",
    "    norm = Normalize(vmin=np.nanmin(data), vmax=np.nanmax(data))\n",
    "    sm = ScalarMappable(norm=norm, cmap='coolwarm')\n",
    "    sm.set_array([])  # for the colorbar\n",
    "\n",
    "    # Draw one circle per cell\n",
    "    h_spacing   = 1.3           # multiplier to separate columns\n",
    "    max_radius  = 0.40\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            val = data[i, j]\n",
    "            if np.isnan(val):                                 # skip empty cells\n",
    "                continue\n",
    "            # scale radius ∝ √value so area is proportional\n",
    "            radius = np.sqrt(val / norm.vmax) * max_radius\n",
    "            x      = j * h_spacing          # apply horizontal spacing\n",
    "            y      = i\n",
    "\n",
    "            ax.add_patch(\n",
    "                Circle((x, y), radius=radius,\n",
    "                       facecolor=sm.to_rgba(val),\n",
    "                       edgecolor='grey', lw=0.5)\n",
    "            )\n",
    "\n",
    "            # bold percentage text\n",
    "            text_col = 'white' if val < (norm.vmin + norm.vmax) / 3 else 'black'\n",
    "            ax.text(x, y, f\"{val*100:.0f}%\",\n",
    "                    ha='center', va='center',\n",
    "                    color=text_col, fontweight='bold')\n",
    "\n",
    "    # ── ticks, labels, limits ──────────────────────────────────────────────────\n",
    "    xtick_pos = [i * h_spacing for i in range(n_cols)]\n",
    "    ax.set_xticks(xtick_pos)\n",
    "    ax.set_xticklabels(\n",
    "        [col.replace(key + '_', '') for col in matrix.columns],\n",
    "        rotation=0, ha='center'\n",
    "    )\n",
    "    ax.set_yticks(np.arange(n_rows))\n",
    "    ax.set_yticklabels(matrix.index)\n",
    "\n",
    "    ax.set_xlim(-0.5 * h_spacing, (n_cols - 1) * h_spacing + 0.5 * h_spacing)\n",
    "    ax.set_ylim(n_rows - 0.5, -0.5)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # remove the four plot spines (frame) but keep the ticks\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    # add the colorbar\n",
    "    cbar = fig.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n",
    "    cbar.outline.set_visible(False)  # This removes the colorbar's surrounding frame\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_quantitative_other_strategy_heatmap(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ccc2a-447e-4dca-82d6-afc9e90f32d4",
   "metadata": {},
   "source": [
    "## Average Response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec880db7-7247-4e18-98a8-3a91310d969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_response_time(games_df, config_col=\"gameConfig\"):\n",
    "    # 1) Convert the time columns to datetime (if they're not already).\n",
    "    #    If they're already datetime, you can skip this step.\n",
    "    games_df['createdAt'] = pd.to_datetime(games_df['createdAt'], errors='coerce')\n",
    "    games_df['updatedAt'] = pd.to_datetime(games_df['updatedAt'], errors='coerce')\n",
    "\n",
    "    # 2) Compute the duration of each game in seconds (or minutes/hours if you prefer).\n",
    "    games_df['game_duration_seconds'] = (\n",
    "        games_df['updatedAt'] - games_df['createdAt']\n",
    "    ).dt.total_seconds()\n",
    "\n",
    "    # 3) Group by configuration and compute the average game duration.\n",
    "    grouped = (\n",
    "        games_df\n",
    "        .groupby(config_col)['game_duration_seconds']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'game_duration_seconds': 'average_game_duration_seconds'})\n",
    "    )\n",
    "\n",
    "    return grouped\n",
    "    \n",
    "time_df = games_df[['gameId', 'createdAt', 'updatedAt']]\n",
    "# Merge on 'gameId'\n",
    "merged_df = pd.merge(results_df, time_df, on='gameId', how='left', suffixes=('_orig', ''))\n",
    "player_id_array = [\"DvplG2Kz\", \"IfM2wWHp\", \"1zx9ju2S\", \"BVSUju5U\", \"lW70ICul\", \"OZ52imkd\", \"GorQHcOB\", \"8PSrn9JD\", \"u5LgXigL\",\n",
    "                  \"1Ax1SPCe\", \"l8ND7njk\", \"sfiXibsa\", \"PvUHGrDy\", \"MO2pWpjE\", \"gsbTiZwO\", \"gDnhDODC\", \"Ska8rixW\", \"6DbWtL5r\",\n",
    "                  \"TCFqdHBb\", \"wQhT1jrv\"]\n",
    "filtered_df = results_df[merged_df[\"playerId\"].isin(player_id_array)]\n",
    "filtered_df = results_df[(merged_df[\"roundCount\"] > 2) & (results_df[\"roundCount\"] <= 16)]\n",
    "\n",
    "# Example usage:\n",
    "results = analyze_response_time(filtered_df, config_col=\"gameConfig\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacea7f6-0148-4c98-b33e-d0a8a62bdc40",
   "metadata": {},
   "source": [
    "## Example dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a4fac-ca6e-4d6a-a695-019e68921562",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e30aa7-d99b-4e33-8dd7-428dceeb923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"word2vec\"\n",
    "filtered_df = get_embeddings_for_table(filtered_df, model_name=embedding_model,)\n",
    "filtered_df = calculate_pca_for_embeddings(\n",
    "    filtered_df,\n",
    "    model_name=embedding_model,\n",
    "    num_pca_components=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4a815-91a9-4f2c-a3fd-550280e81284",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[\"botId\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf04e15-4ff1-4593-80e6-efd8da6d3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df.copy().reset_index()\n",
    "\n",
    "df[df[\"botId\"] == \"gpt-4o\"][df[\"roundCount\"] == 7][[\"gameId\", \"roundCount\", \"wordsPlayed1\", \"wordsPlayed2\", \"embedding1_word2vec\", \"embedding2_word2vec\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3d893-e59c-4441-ac6b-f867a2336ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from visualization import create_fixed_color_lines\n",
    "\n",
    "df = filtered_df.copy().reindex()\n",
    "\n",
    "tryout = 24\n",
    "\n",
    "words_player1 = eval(df['word_my'].iloc[tryout])\n",
    "words_player2 = eval(df['word_opponent'].iloc[tryout])\n",
    "embeddings_1 = df['embedding1_word2vec'].iloc[tryout]\n",
    "embeddings_2 = df['embedding2_word2vec'].iloc[tryout]\n",
    "\n",
    "print(words_player1)\n",
    "print(words_player2)\n",
    "print(df['gameConfig'].iloc[tryout])\n",
    "\n",
    "# merge the embeddings\n",
    "embeddings = embeddings_1 + embeddings_2\n",
    "\n",
    "# Use PCA to reduce to 3 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit(np.array(embeddings))\n",
    "reduced_embeddings_1 = pca.transform(embeddings_1)\n",
    "reduced_embeddings_2 = pca.transform(embeddings_2)\n",
    "\n",
    "# Create 3D scatter plot for player 1 with text labels showing index and word\n",
    "trace1 = go.Scatter3d(\n",
    "    x=reduced_embeddings_1[:, 0],\n",
    "    y=reduced_embeddings_1[:, 1],\n",
    "    z=reduced_embeddings_1[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=4, color='blue'),\n",
    "    text=[f\"{i}: {word}\" for i, word in enumerate(words_player1)],\n",
    "    name='Player'\n",
    ")\n",
    "\n",
    "# Create 3D scatter plot for player 2 with text labels showing index and word\n",
    "trace2 = go.Scatter3d(\n",
    "    x=reduced_embeddings_2[:, 0],\n",
    "    y=reduced_embeddings_2[:, 1],\n",
    "    z=reduced_embeddings_2[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=4, color='red'),\n",
    "    text=[f\"{i}: {word}\" for i, word in enumerate(words_player2)],\n",
    "    name='Bot'\n",
    ")\n",
    "\n",
    "# If the game converged, highlight the final point with a special marker\n",
    "if words_player2[-1] == words_player1[-1]:\n",
    "    print(\"won\")\n",
    "    last_point_player = go.Scatter3d(\n",
    "        x=[reduced_embeddings_2[-1, 0]],\n",
    "        y=[reduced_embeddings_2[-1, 1]],\n",
    "        z=[reduced_embeddings_2[-1, 2]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=8, color='green', symbol=\"diamond-open\"),\n",
    "        text=[f\"{len(words_player2)-1}: {words_player2[-1]}\"],\n",
    "        name='Final word'\n",
    "    )\n",
    "\n",
    "print(len(words_player1))\n",
    "# Create gradient lines for both players using Plotly colormaps\n",
    "lines_player1 = create_fixed_color_lines(reduced_embeddings_1, len(words_player1), 'blue')\n",
    "lines_player2 = create_fixed_color_lines(reduced_embeddings_2, len(words_player2), 'red')\n",
    "\n",
    "# Combine all traces\n",
    "data = [trace1, trace2] + lines_player1 + lines_player2\n",
    "if words_player2[-1] == words_player1[-1]:\n",
    "    data = data + [last_point_player]\n",
    "\n",
    "# Define layout with larger figure size\n",
    "layout = go.Layout(\n",
    "    title='3D Scatter Plot with Colormap Gradient Lines',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='PCA1'),\n",
    "        yaxis=dict(title='PCA2'),\n",
    "        zaxis=dict(title='PCA3'),\n",
    "    ),\n",
    "    legend_title_text='Legend',\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Create figure and show\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab2e27-01c6-470d-bd6f-e976f1d7c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5a927-7d45-4c3f-846d-b05c034c334b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "words_env",
   "language": "python",
   "name": "words_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
